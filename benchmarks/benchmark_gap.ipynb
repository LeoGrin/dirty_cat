{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/datasets/_fetching.py:626: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(info[\"path\"], **read_csv_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from dirty_cat import TableVectorizer\n",
    "from dirty_cat.datasets import fetch_traffic_violations\n",
    "\n",
    "ds = fetch_traffic_violations()\n",
    "#sv = TableVectorizer()\n",
    "#sv.fit(ds.X)  # This will take a while...\n",
    "\n",
    "#print(sv.transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dirty_cat import GapEncoder\n",
    "\n",
    "gap = GapEncoder(batch_size=2048, n_jobs=-1, hashing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_cols = [\"seqid\", \"description\", \"location\", \"search_reason_for_stop\", \"state\", \"make\", \"model\", \"charge\", \"driver_city\", \"driver_state\", \"dl_state\", \"geolocation\"]\n",
    "#high_cardinality_cols = [\"description\", \"location\", \"search_reason_for_stop\", \"state\", \"make\", \"model\", \"charge\", \"driver_city\", \"driver_state\", \"dl_state\", \"geolocation\"]\n",
    "#high_cardinality_cols = [\"seqid\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.X[high_cardinality_cols]\n",
    "# only keep the first 10000 rows\n",
    "data = data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.arange(100000).reshape(-1, 1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0026\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.54s\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0116\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.71s\n",
      "Batch 49/49 - W change: 0.0091\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.86s\n",
      "Batch 49/49 - W change: 0.0102\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 6.53s\n",
      "Batch 49/49 - W change: 0.0212\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 6.79s\n",
      "Batch 49/49 - W change: 0.0024\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.00s\n",
      "Batch 49/49 - W change: 0.0104\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.11s\n",
      "Batch 49/49 - W change: 0.0084\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.20s\n",
      "Batch 49/49 - W change: 0.0090\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.80s\n",
      "Batch 49/49 - W change: 0.0193\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 6.08s\n",
      "Batch 49/49 - W change: 0.0085\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 9.75s\n",
      "Batch 49/49 - W change: 0.0023\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.06s\n",
      "Batch 49/49 - W change: 0.0083\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.51s\n",
      "Batch 49/49 - W change: 0.0104\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.75s\n",
      "Batch 49/49 - W change: 0.0089\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 6.63s\n",
      "Batch 49/49 - W change: 0.0197\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 16.82s\n",
      "Batch 49/49 - W change: 0.0192\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 6.94s\n",
      "Batch 49/49 - W change: 0.0023\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.19s\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 9.31s\n",
      "Batch 49/49 - W change: 0.0104\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.85s\n",
      "Batch 49/49 - W change: 0.0083\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 6.02s\n",
      "Batch 49/49 - W change: 0.0087\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.85s\n",
      "Batch 49/49 - W change: 0.0023\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.76s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "Batch 49/49 - W change: 0.0191\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.94s\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0103\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.41s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "Batch 49/49 - W change: 0.0083\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.53s\n",
      "fit ngrams count vectorizer done3\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0084\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.48s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 8.64s\n",
      "Batch 49/49 - W change: 0.0191\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.81s\n",
      "Batch 49/49 - W change: 0.0185\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 12.73s\n",
      "Batch 49/49 - W change: 0.0125\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.88s\n",
      "Batch 49/49 - W change: 0.0015\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 4.69s\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "Batch 49/49 - W change: 0.0015\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 4.93s\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0133\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 29.68s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 4.47s\n",
      "Batch 49/49 - W change: 0.0116\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.44s\n",
      "Batch 49/49 - W change: 0.0013\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 4.41s\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 7.84s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 4.28s\n",
      "Batch 49/49 - W change: 0.0013\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 4.19s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 4.92s\n",
      "Batch 49/49 - W change: 0.0186\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 11.81s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 3.62s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 3.72s\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 7.04s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 4.50s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.07s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.24s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.18s\n",
      "Batch 49/49 - W change: 0.0186\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 10.37s\n",
      "Batch 49/49 - W change: 0.0063\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 20.71s\n",
      "Batch 49/49 - W change: 0.0120\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 22.29s\n",
      "Batch 49/49 - W change: 0.0187\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.66s\n",
      "Batch 49/49 - W change: 0.0052\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 7.57s\n",
      "Batch 49/49 - W change: 0.0117\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 9.83s\n",
      "Batch 49/49 - W change: 0.0051\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.90s\n",
      "Batch 49/49 - W change: 0.0050\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.46s\n",
      "Batch 49/49 - W change: 0.0116\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 8.80s\n",
      "Batch 49/49 - W change: 0.0050\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.07s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 7.77s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GapEncoder(batch_size=2048, hashing=True, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GapEncoder</label><div class=\"sk-toggleable__content\"><pre>GapEncoder(batch_size=2048, hashing=True, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GapEncoder(batch_size=2048, hashing=True, n_jobs=-1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit GapEncoderColumn\n",
      "Score: 37844715.045767166\n",
      "Batch 782/782 - W change: 0.0171\n",
      "Tolerance:  0.0001\n",
      "Score: 19796404.739312764\n",
      "Epoch 1/5 - Time: 11.43s\n",
      "Batch 782/782 - W change: 0.0171\n",
      "Tolerance:  0.0001\n",
      "Score: 19789466.194309905\n",
      "Epoch 2/5 - Time: 11.21s\n",
      "Batch 782/782 - W change: 0.0171\n",
      "Tolerance:  0.0001\n",
      "Score: 19719531.34417127\n",
      "Epoch 3/5 - Time: 11.07s\n",
      "Batch 297/782\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gap\u001b[39m.\u001b[39;49mfit(data)\n",
      "File \u001b[0;32m~/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/_gap_encoder.py:825\u001b[0m, in \u001b[0;36mGapEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_models_ \u001b[39m=\u001b[39m []\n\u001b[1;32m    821\u001b[0m \u001b[39m# for k in range(X.shape[1]):\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[39m#     col_enc = self._create_column_gap_encoder()\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39m#     self.fitted_models_.append(col_enc.fit(X[:, k]))\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[39m# Parallelize the encoding of each column\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_models_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    826\u001b[0m     delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_column_gap_encoder()\u001b[39m.\u001b[39;49mfit)(X[:, k])\n\u001b[1;32m    827\u001b[0m     \u001b[39mfor\u001b[39;49;00m k \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(X\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    828\u001b[0m )\n\u001b[1;32m    829\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/_gap_encoder.py:296\u001b[0m, in \u001b[0;36mGapEncoderColumn.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    285\u001b[0m unq_H[unq_idx] \u001b[39m=\u001b[39m _multiplicative_update_h(\n\u001b[1;32m    286\u001b[0m     unq_V[unq_idx],\n\u001b[1;32m    287\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m     gamma_scale_prior\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma_scale_prior,\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    295\u001b[0m \u001b[39m# Update the topics self.W_\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m _multiplicative_update_w(\n\u001b[1;32m    297\u001b[0m     unq_V[idx],\n\u001b[1;32m    298\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_,\n\u001b[1;32m    299\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA_,\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB_,\n\u001b[1;32m    301\u001b[0m     unq_H[idx],\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrescale_W,\n\u001b[1;32m    303\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrho_,\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    306\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m n_batch \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    307\u001b[0m     \u001b[39m# Compute the norm of the update of W in the last batch\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     W_change \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_ \u001b[39m-\u001b[39m W_last) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(W_last)\n",
      "File \u001b[0;32m~/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/_gap_encoder.py:1005\u001b[0m, in \u001b[0;36m_multiplicative_update_w\u001b[0;34m(Vt, W, A, B, Ht, rescale_W, rho)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[39mMultiplicative update step for the topics W.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m A \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m rho\n\u001b[0;32m-> 1005\u001b[0m A \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m W \u001b[39m*\u001b[39m safe_sparse_dot(Ht\u001b[39m.\u001b[39mT, Vt\u001b[39m.\u001b[39mmultiply(\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39;49mdot(Ht, W) \u001b[39m+\u001b[39m \u001b[39m1e-10\u001b[39m)))\n\u001b[1;32m   1006\u001b[0m B \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m rho\n\u001b[1;32m   1007\u001b[0m B \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m Ht\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gap.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments\n",
    "# init var takes ~ 1 min, we should go to hashing\n",
    "\n",
    "# easily parallelizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many cpus are available\n",
    "import joblib\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dirty_cat import MinHashEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " enc = MinHashEncoder(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [['paris, FR'], ['Paris'], ['London, UK'], ['London']]\n",
    "X2 = [['paris, FR'], ['Paris'], ['London, UK'], ['London']]\n",
    "import numpy as np\n",
    "X = np.concatenate((X1, X2), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['paris, FR', 'paris, FR'],\n",
       "       ['Paris', 'Paris'],\n",
       "       ['London, UK', 'London, UK'],\n",
       "       ['London', 'London']], dtype='<U10')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   paris, FR\n",
       "1       Paris\n",
       "2  London, UK\n",
       "3      London"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinHashEncoder(n_components=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinHashEncoder</label><div class=\"sk-toggleable__content\"><pre>MinHashEncoder(n_components=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinHashEncoder(n_components=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          fdcc1a6b-4854-4cde-bb60-248f478fa5b6\n",
       "1          842dad60-5edf-47a8-9e94-c7e6da729498\n",
       "2          4db837cc-f2fa-4a5b-9ac8-37698492b5f9\n",
       "3          79761295-50f6-4336-8b48-fdf55e87a326\n",
       "4          f9a7a508-386c-466e-95b2-dbf26d7d59fe\n",
       "                           ...                 \n",
       "1578149    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578150    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578151    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578152    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578153    845c2732-d70b-42ef-bde8-603f9563aa28\n",
       "Name: seqid, Length: 1578154, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.X[\"seqid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirty_cat_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
