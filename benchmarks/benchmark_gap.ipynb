{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/__8z8cpn6gs04465sq9g1nq80000gn/T/ipykernel_79667/1654667150.py:2: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"benchmarks/train.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"benchmarks/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Dict, List, Literal, Optional, Tuple, Union\n",
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from pandas._libs.tslibs.parsing import guess_datetime_format\n",
    "from pandas.core.dtypes.base import ExtensionDtype\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.base import TransformerMixin, clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.deprecation import deprecated\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from dirty_cat import DatetimeEncoder, GapEncoder\n",
    "from dirty_cat._utils import parse_version\n",
    "\n",
    "# Required for ignoring lines too long in the docstrings\n",
    "# flake8: noqa: E501\n",
    "\n",
    "\n",
    "def _infer_date_format(date_column: pd.Series, n_trials: int = 100) -> Optional[str]:\n",
    "    \"\"\"Infer the date format of a date column,\n",
    "    by finding a format which should work for all dates in the column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    date_column : :class:`~pandas.Series`\n",
    "        A column of dates, as strings.\n",
    "    n_trials : int, default=100\n",
    "        Number of rows to use to infer the date format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Optional[str]\n",
    "        The date format inferred from the column.\n",
    "        If no format could be inferred, returns None.\n",
    "    \"\"\"\n",
    "    if len(date_column) == 0:\n",
    "        return\n",
    "    date_column_sample = date_column.dropna().sample(\n",
    "        frac=min(n_trials / len(date_column), 1), random_state=42\n",
    "    )\n",
    "    # try to infer the date format\n",
    "    # see if either dayfirst or monthfirst works for all the rows\n",
    "    with warnings.catch_warnings():\n",
    "        # pandas warns when dayfirst is not strictly applied\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        date_format_monthfirst = date_column_sample.apply(\n",
    "            lambda x: guess_datetime_format(x)\n",
    "        )\n",
    "        date_format_dayfirst = date_column_sample.apply(\n",
    "            lambda x: guess_datetime_format(x, dayfirst=True),\n",
    "        )\n",
    "        print(date_format_monthfirst)\n",
    "        print(date_format_dayfirst)\n",
    "    # if one row could not be parsed, return None\n",
    "    if date_format_monthfirst.isnull().any() or date_format_dayfirst.isnull().any():\n",
    "        return\n",
    "    # even with dayfirst=True, monthfirst format can be inferred\n",
    "    # so we need to check if the format is the same for all the rows\n",
    "    elif date_format_monthfirst.nunique() == 1:\n",
    "        # one monthfirst format works for all the rows\n",
    "        # check if another format works for all the rows\n",
    "        # if so, raise a warning\n",
    "        if date_format_dayfirst.nunique() == 1:\n",
    "            # check if monthfirst and dayfirst haven't found the same format\n",
    "            if date_format_monthfirst.iloc[0] != date_format_dayfirst.iloc[0]:\n",
    "                warnings.warn(\n",
    "                    f\"\"\"\n",
    "                    Both {date_format_monthfirst.iloc[0]} and {date_format_dayfirst.iloc[0]} are valid\n",
    "                    formats for the dates in column {date_column.name}.\n",
    "                    Format {date_format_monthfirst.iloc[0]} will be used.\n",
    "                    \"\"\",\n",
    "                    UserWarning,\n",
    "                    stacklevel=2,\n",
    "                )\n",
    "        return date_format_monthfirst.iloc[0]\n",
    "    elif date_format_dayfirst.nunique() == 1:\n",
    "        # only this format works for all the rows\n",
    "        return date_format_dayfirst.iloc[0]\n",
    "    else:\n",
    "        # more than two different formats were found\n",
    "        # TODO: maybe we could deal with this case\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_datetime_format(\"12/1/22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         12/1/22\n",
       "1          2/3/05\n",
       "2          2/1/20\n",
       "3         10/7/99\n",
       "4         10/7/99\n",
       "           ...   \n",
       "112588     1/1/23\n",
       "112589     1/1/23\n",
       "112590     1/1/23\n",
       "112591     1/1/23\n",
       "112592    1/30/23\n",
       "Name: HIREDT, Length: 112593, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HIREDT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/__8z8cpn6gs04465sq9g1nq80000gn/T/ipykernel_79667/3117163595.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(df[\"HIREDT\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        2022-12-01\n",
       "1        2005-02-03\n",
       "2        2020-02-01\n",
       "3        1999-10-07\n",
       "4        1999-10-07\n",
       "            ...    \n",
       "112588   2023-01-01\n",
       "112589   2023-01-01\n",
       "112590   2023-01-01\n",
       "112591   2023-01-01\n",
       "112592   2023-01-30\n",
       "Name: HIREDT, Length: 112593, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df[\"HIREDT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_datetime_format(\"30/01/23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/__8z8cpn6gs04465sq9g1nq80000gn/T/ipykernel_78607/3117163595.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(df[\"HIREDT\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        2022-12-01\n",
       "1        2005-02-03\n",
       "2        2020-02-01\n",
       "3        1999-10-07\n",
       "4        1999-10-07\n",
       "            ...    \n",
       "112588   2023-01-01\n",
       "112589   2023-01-01\n",
       "112590   2023-01-01\n",
       "112591   2023-01-01\n",
       "112592   2023-01-30\n",
       "Name: HIREDT, Length: 112593, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df[\"HIREDT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21229     None\n",
      "11040     None\n",
      "82591     None\n",
      "55539     None\n",
      "35412     None\n",
      "          ... \n",
      "24263     None\n",
      "17713     None\n",
      "85486     None\n",
      "108109    None\n",
      "50550     None\n",
      "Name: HIREDT, Length: 100, dtype: object\n",
      "21229     None\n",
      "11040     None\n",
      "82591     None\n",
      "55539     None\n",
      "35412     None\n",
      "          ... \n",
      "24263     None\n",
      "17713     None\n",
      "85486     None\n",
      "108109    None\n",
      "50550     None\n",
      "Name: HIREDT, Length: 100, dtype: object\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(_infer_date_format(df[\"HIREDT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 880/880 - W change: 0.1339\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 6.86s\n",
      "Batch 880/880 - W change: 0.1350\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 7.84s\n",
      "Batch 880/880 - W change: 0.1350\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 6.00s\n",
      "Batch 880/880 - W change: 0.1350\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.89s\n",
      "Batch 880/880 - W change: 0.1352\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.78s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 880/880 - W change: 0.0508\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 9.17s\n",
      "Batch 880/880 - W change: 0.0972\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 9.73s\n",
      "Batch 880/880 - W change: 0.0960\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 8.65s\n",
      "Batch 880/880 - W change: 0.0953\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 8.32s\n",
      "Batch 880/880 - W change: 0.0946\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 9.39s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 880/880 - W change: 0.0257\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 11.96s\n",
      "Batch 880/880 - W change: 0.0239\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 15.26s\n",
      "Batch 880/880 - W change: 0.0235\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 16.82s\n",
      "Batch 880/880 - W change: 0.0235\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 14.80s\n",
      "Batch 880/880 - W change: 0.0234\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 14.76s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 880/880 - W change: 0.0350\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 8.03s\n",
      "Batch 880/880 - W change: 0.0347\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 7.76s\n",
      "Batch 880/880 - W change: 0.0341\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 7.77s\n",
      "Batch 880/880 - W change: 0.0341\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 7.20s\n",
      "Batch 880/880 - W change: 0.0341\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 7.85s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.000000e+00, 0.000000e+00, 1.000000e+00, ..., 3.244800e+04,\n",
       "        1.000000e+00,          nan],\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, ..., 3.737500e+04,\n",
       "                 nan, 1.000000e+00],\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, ..., 5.911500e+04,\n",
       "                 nan,          nan],\n",
       "       ...,\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, ..., 1.576554e+06,\n",
       "                 nan,          nan],\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, ..., 1.577374e+06,\n",
       "                 nan,          nan],\n",
       "       [0.000000e+00, 0.000000e+00, 0.000000e+00, ..., 1.579244e+06,\n",
       "                 nan,          nan]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dirty_cat import TableVectorizer\n",
    "from dirty_cat.datasets import fetch_traffic_violations\n",
    "\n",
    "tb = TableVectorizer()\n",
    "tb.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TableVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TableVectorizer</label><div class=\"sk-toggleable__content\"><pre>TableVectorizer()</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">low_card_cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;MI&#x27;, &#x27;RACE&#x27;, &#x27;SEX&#x27;, &#x27;EMPTYPE&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">high_card_cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;NAME&#x27;, &#x27;JOBCLASS&#x27;, &#x27;JC.TITLE&#x27;, &#x27;HIREDT&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GapEncoder</label><div class=\"sk-toggleable__content\"><pre>GapEncoder(n_components=30)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Unnamed: 0&#x27;, &#x27;AGY&#x27;, &#x27;RATE&#x27;, &#x27;HRSWKD&#x27;, &#x27;ANNUAL&#x27;, &#x27;STATENUM&#x27;, &#x27;multiple_full_time_jobs&#x27;, &#x27;combined_multiple_jobs&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "TableVectorizer()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/datasets/_fetching.py:626: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(info[\"path\"], **read_csv_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from dirty_cat import TableVectorizer\n",
    "from dirty_cat.datasets import fetch_traffic_violations\n",
    "\n",
    "ds = fetch_traffic_violations()\n",
    "#sv = TableVectorizer()\n",
    "#sv.fit(ds.X)  # This will take a while...\n",
    "\n",
    "#print(sv.transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dirty_cat import GapEncoder\n",
    "\n",
    "gap = GapEncoder(batch_size=2048, n_jobs=-1, hashing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_cols = [\"seqid\", \"description\", \"location\", \"search_reason_for_stop\", \"state\", \"make\", \"model\", \"charge\", \"driver_city\", \"driver_state\", \"dl_state\", \"geolocation\"]\n",
    "#high_cardinality_cols = [\"description\", \"location\", \"search_reason_for_stop\", \"state\", \"make\", \"model\", \"charge\", \"driver_city\", \"driver_state\", \"dl_state\", \"geolocation\"]\n",
    "#high_cardinality_cols = [\"seqid\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.X[high_cardinality_cols]\n",
    "# only keep the first 10000 rows\n",
    "data = data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.arange(100000).reshape(-1, 1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0026\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.54s\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0116\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.71s\n",
      "Batch 49/49 - W change: 0.0091\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.86s\n",
      "Batch 49/49 - W change: 0.0102\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 6.53s\n",
      "Batch 49/49 - W change: 0.0212\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 6.79s\n",
      "Batch 49/49 - W change: 0.0024\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.00s\n",
      "Batch 49/49 - W change: 0.0104\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.11s\n",
      "Batch 49/49 - W change: 0.0084\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.20s\n",
      "Batch 49/49 - W change: 0.0090\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.80s\n",
      "Batch 49/49 - W change: 0.0193\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 6.08s\n",
      "Batch 49/49 - W change: 0.0085\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 9.75s\n",
      "Batch 49/49 - W change: 0.0023\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.06s\n",
      "Batch 49/49 - W change: 0.0083\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.51s\n",
      "Batch 49/49 - W change: 0.0104\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.75s\n",
      "Batch 49/49 - W change: 0.0089\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 6.63s\n",
      "Batch 49/49 - W change: 0.0197\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 16.82s\n",
      "Batch 49/49 - W change: 0.0192\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 6.94s\n",
      "Batch 49/49 - W change: 0.0023\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.19s\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 9.31s\n",
      "Batch 49/49 - W change: 0.0104\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.85s\n",
      "Batch 49/49 - W change: 0.0083\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 6.02s\n",
      "Batch 49/49 - W change: 0.0087\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.85s\n",
      "Batch 49/49 - W change: 0.0023\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.76s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "Batch 49/49 - W change: 0.0191\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.94s\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0103\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.41s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "Batch 49/49 - W change: 0.0083\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.53s\n",
      "fit ngrams count vectorizer done3\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0084\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.48s\n",
      "Fit GapEncoderColumn\n",
      "init ngrams count vectorizer\n",
      "fit ngrams count vectorizer\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 8.64s\n",
      "Batch 49/49 - W change: 0.0191\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.81s\n",
      "Batch 49/49 - W change: 0.0185\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 12.73s\n",
      "Batch 49/49 - W change: 0.0125\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 5.88s\n",
      "Batch 49/49 - W change: 0.0015\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 4.69s\n",
      "fit ngrams count vectorizer done\n",
      "fit ngrams count vectorizer done2\n",
      "Batch 49/49 - W change: 0.0015\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 4.93s\n",
      "fit ngrams count vectorizer done3\n",
      "Batch 49/49 - W change: 0.0133\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 29.68s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 4.47s\n",
      "Batch 49/49 - W change: 0.0116\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 5.44s\n",
      "Batch 49/49 - W change: 0.0013\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 4.41s\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 7.84s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 4.28s\n",
      "Batch 49/49 - W change: 0.0013\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 4.19s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 4.92s\n",
      "Batch 49/49 - W change: 0.0186\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 11.81s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 3.62s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 3.72s\n",
      "Batch 49/49 - W change: 0.0078\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 7.04s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 4.50s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.07s\n",
      "Batch 49/49 - W change: 0.0014\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.24s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.18s\n",
      "Batch 49/49 - W change: 0.0186\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 10.37s\n",
      "Batch 49/49 - W change: 0.0063\n",
      "Tolerance:  0.0001\n",
      "Epoch 1/5 - Time: 20.71s\n",
      "Batch 49/49 - W change: 0.0120\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 22.29s\n",
      "Batch 49/49 - W change: 0.0187\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 4.66s\n",
      "Batch 49/49 - W change: 0.0052\n",
      "Tolerance:  0.0001\n",
      "Epoch 2/5 - Time: 7.57s\n",
      "Batch 49/49 - W change: 0.0117\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 9.83s\n",
      "Batch 49/49 - W change: 0.0051\n",
      "Tolerance:  0.0001\n",
      "Epoch 3/5 - Time: 5.90s\n",
      "Batch 49/49 - W change: 0.0050\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 5.46s\n",
      "Batch 49/49 - W change: 0.0116\n",
      "Tolerance:  0.0001\n",
      "Epoch 4/5 - Time: 8.80s\n",
      "Batch 49/49 - W change: 0.0050\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 5.07s\n",
      "Batch 49/49 - W change: 0.0115\n",
      "Tolerance:  0.0001\n",
      "Epoch 5/5 - Time: 7.77s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GapEncoder(batch_size=2048, hashing=True, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GapEncoder</label><div class=\"sk-toggleable__content\"><pre>GapEncoder(batch_size=2048, hashing=True, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GapEncoder(batch_size=2048, hashing=True, n_jobs=-1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit GapEncoderColumn\n",
      "Score: 37844715.045767166\n",
      "Batch 782/782 - W change: 0.0171\n",
      "Tolerance:  0.0001\n",
      "Score: 19796404.739312764\n",
      "Epoch 1/5 - Time: 11.43s\n",
      "Batch 782/782 - W change: 0.0171\n",
      "Tolerance:  0.0001\n",
      "Score: 19789466.194309905\n",
      "Epoch 2/5 - Time: 11.21s\n",
      "Batch 782/782 - W change: 0.0171\n",
      "Tolerance:  0.0001\n",
      "Score: 19719531.34417127\n",
      "Epoch 3/5 - Time: 11.07s\n",
      "Batch 297/782\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gap\u001b[39m.\u001b[39;49mfit(data)\n",
      "File \u001b[0;32m~/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/_gap_encoder.py:825\u001b[0m, in \u001b[0;36mGapEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_models_ \u001b[39m=\u001b[39m []\n\u001b[1;32m    821\u001b[0m \u001b[39m# for k in range(X.shape[1]):\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[39m#     col_enc = self._create_column_gap_encoder()\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39m#     self.fitted_models_.append(col_enc.fit(X[:, k]))\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[39m# Parallelize the encoding of each column\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_models_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    826\u001b[0m     delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_column_gap_encoder()\u001b[39m.\u001b[39;49mfit)(X[:, k])\n\u001b[1;32m    827\u001b[0m     \u001b[39mfor\u001b[39;49;00m k \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(X\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    828\u001b[0m )\n\u001b[1;32m    829\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/mambaforge/envs/dirty_cat_py3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/_gap_encoder.py:296\u001b[0m, in \u001b[0;36mGapEncoderColumn.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    285\u001b[0m unq_H[unq_idx] \u001b[39m=\u001b[39m _multiplicative_update_h(\n\u001b[1;32m    286\u001b[0m     unq_V[unq_idx],\n\u001b[1;32m    287\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m     gamma_scale_prior\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma_scale_prior,\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    295\u001b[0m \u001b[39m# Update the topics self.W_\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m _multiplicative_update_w(\n\u001b[1;32m    297\u001b[0m     unq_V[idx],\n\u001b[1;32m    298\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_,\n\u001b[1;32m    299\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA_,\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB_,\n\u001b[1;32m    301\u001b[0m     unq_H[idx],\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrescale_W,\n\u001b[1;32m    303\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrho_,\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    306\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m n_batch \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    307\u001b[0m     \u001b[39m# Compute the norm of the update of W in the last batch\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     W_change \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_ \u001b[39m-\u001b[39m W_last) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(W_last)\n",
      "File \u001b[0;32m~/PycharmProjects/dirty_cat_forks/dirty_cat/dirty_cat/_gap_encoder.py:1005\u001b[0m, in \u001b[0;36m_multiplicative_update_w\u001b[0;34m(Vt, W, A, B, Ht, rescale_W, rho)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[39mMultiplicative update step for the topics W.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m A \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m rho\n\u001b[0;32m-> 1005\u001b[0m A \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m W \u001b[39m*\u001b[39m safe_sparse_dot(Ht\u001b[39m.\u001b[39mT, Vt\u001b[39m.\u001b[39mmultiply(\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39;49mdot(Ht, W) \u001b[39m+\u001b[39m \u001b[39m1e-10\u001b[39m)))\n\u001b[1;32m   1006\u001b[0m B \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m rho\n\u001b[1;32m   1007\u001b[0m B \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m Ht\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gap.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments\n",
    "# init var takes ~ 1 min, we should go to hashing\n",
    "\n",
    "# easily parallelizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many cpus are available\n",
    "import joblib\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dirty_cat import MinHashEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " enc = MinHashEncoder(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [['paris, FR'], ['Paris'], ['London, UK'], ['London']]\n",
    "X2 = [['paris, FR'], ['Paris'], ['London, UK'], ['London']]\n",
    "import numpy as np\n",
    "X = np.concatenate((X1, X2), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['paris, FR', 'paris, FR'],\n",
       "       ['Paris', 'Paris'],\n",
       "       ['London, UK', 'London, UK'],\n",
       "       ['London', 'London']], dtype='<U10')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   paris, FR\n",
       "1       Paris\n",
       "2  London, UK\n",
       "3      London"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinHashEncoder(n_components=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinHashEncoder</label><div class=\"sk-toggleable__content\"><pre>MinHashEncoder(n_components=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinHashEncoder(n_components=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          fdcc1a6b-4854-4cde-bb60-248f478fa5b6\n",
       "1          842dad60-5edf-47a8-9e94-c7e6da729498\n",
       "2          4db837cc-f2fa-4a5b-9ac8-37698492b5f9\n",
       "3          79761295-50f6-4336-8b48-fdf55e87a326\n",
       "4          f9a7a508-386c-466e-95b2-dbf26d7d59fe\n",
       "                           ...                 \n",
       "1578149    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578150    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578151    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578152    b1463ded-4b1a-4e7f-ada9-9211bbdc1cbb\n",
       "1578153    845c2732-d70b-42ef-bde8-603f9563aa28\n",
       "Name: seqid, Length: 1578154, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.X[\"seqid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirty_cat_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
